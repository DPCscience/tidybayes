---
title: "Extracting tidy samples from rstanarm"
author: "Matthew Kay"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    df_print: kable
vignette: >
  %\VignetteIndexEntry{Extracting tidy data from rstanarm}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
<style type="text/css">
.kable-table table {
  margin-left: 0;
}
img {
  border: none;
}
</style>


## Introduction
  
This vignette describes how to use the `tidybayes` package to extract tidy samples from `rstanarm`. For a more general introduction to `tidybayes` and its use on more general-purpose sampling languages (like Stan and JAGS), see [vignette("tidybayes")](tidybayes.html).
  
The default output data formats of popular samplers like JAGS and Stan often don't quite conform to the ideal of [tidy data](http://dx.doi.org/10.18637/jss.v059.i10). Output formats will often be in matrix form (requiring conversion for use with libraries like ggplot). `tidybayes` automates munging the samples into tidy formats.
  
  
## Setup
  
The following libraries are required to run this vignette:
  
```{r setup, message = FALSE, warning = FALSE}
library(magrittr)
library(dplyr)
library(tidybayes)
library(ggplot2)
library(ggstance)
library(rstan)
library(rstanarm)
```

These options help Stan run faster:

```{r, eval=FALSE}
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

```{r hidden_options, include=FALSE}
# While the previous code chunk is the actual recommended approach,
# CRAN vignette building policy limits us to 2 cores, so we use at most
# 2 to build this vignette (but show the previous chunk to
# the reader as a best pratice example)
rstan_options(auto_write = TRUE)
options(mc.cores = min(2, parallel::detectCores()))

#ggplot options
theme_set(theme_light())

#figure options
knitr::opts_chunk$set(fig.width = 6, fig.height = 4)
```


## Example dataset

To demonstrate `tidybayes`, we will use a simple dataset with 10 observations from 5 conditions each:

```{r}
set.seed(5)
n = 10
n_condition = 5
ABC =
  data_frame(
    condition = rep(c("A","B","C","D","E"), n),
    response = rnorm(n * 5, c(0,1,2,1,-1), 0.5)
  )
```

A snapshot of the data looks like this:

```{r}
head(ABC, 10)
```
*(10 rows of `r nrow(ABC)`)*

This is a typical tidy format data frame: one observation per row. Graphically:

```{r}
ABC %>%
  ggplot(aes(y = condition, x = response)) +
  geom_point()
```

## Model

Let's fit a hierarchical model with shrinkage towards a global mean:

```{r}
m = stan_lmer(response ~ (1|condition), data = ABC, 
  prior = normal(0, 1, autoscale = FALSE),
  prior_aux = student_t(3, 0, 1, autoscale = FALSE),
  adapt_delta = .99)
```

The results look like this:

```{r}
summary(m)
```


## Gathering samples from a fit in tidy-format using `spread_samples`

Now that we have our results, the fun begins: getting the samples out in a tidy format! For example, given these parameters:

- `b[(Intercept) condition:A]`
- `b[(Intercept) condition:B]`
- `b[(Intercept) condition:C]`
- `b[(Intercept) condition:D]`
- `b[(Intercept) condition:E]`

We might want a data frame where each row is a sample from either `b[(Intercept) condition:A]`, `b[(Intercept) condition:B]`, `...:C]`, `...:D]`, or `...:E]`, and where we have columns indexing which iteration of the sampler the sample came from and which condition it is for. That would allow us to easily compute quantities grouped by condition, or generate plots by condition using ggplot, or even merge samples with the original data to plot data and estimates.

The workhorse of `tidybayes` is the `spread_samples` function, which does this extraction for us. It includes a simple specification format that we can use to extract parameters and their indices into tidy-format data frames.

### Gathering parameter indices into a separate column in a tidy format data frame

Given a parameter like this:

`b[(Intercept) condition:D]`

We can provide `spread_samples` with a column specification like this:

`b[term,group,condition]`

Where `term` corresponds to `(Intercept)`, `group` to `condition`, and `condition` to `D`. There is nothing too magical about what `spread_samples` does with this specification: under the hood, it splits the parameter indices by spaces, `:`, and `,`, and lets you assign columns to the resulting indices in order. So `b[(Intercept) condition:D]` has indices `(Intercept)`, `condition`, and `D`, and gather samples lets us extract these indices as columns and get a tidy data frame of samples of `b`:

```{r}
m %>%
  spread_samples(b[term,group,condition]) %>%
  head(10)
```
*(10 rows of `r nrow(spread_samples(m, b[term,group,condition]))`)*

We can choose whatever names we want for the index columns; e.g.: 

```{r}
m %>%
  spread_samples(b[t,g,c]) %>%
  head(10)
```
*(10 rows of `r nrow(spread_samples(m, b[term,group,condition]))`)*

But the more descriptive and less cryptic names from the previous example are probably preferable.

In this particular model, there is only one term (`(Intercept)`) and one group (`condition`), thus we could omit those two indices altogether to just get each `condition` and the value of `b` for that condition:

```{r}
m %>%
  spread_samples(b[,,condition]) %>%
  head(10)
```
*(10 rows of `r nrow(spread_samples(m, b[term,group,condition]))`)*

__Note:__ If you have used `spread_samples` with raw samples from Stan or JAGS, you may be used to using `recover_types` before `spread_samples` to get index column values back (e.g. if the index was a factor). This is not necessary when using `spread_samples` on `rstanarm` models, because those models already contain that information in their parameter names. For more on `recover_types`, see <code>[vignette("tidybayes")](tidybayes.html)</code>.

## Point estimates and intervals

### With simple parameters

`tidybayes` provides a family of functions for generating point estimates and intervals from samples in a tidy format. These functions follow the naming scheme `[mean|median|mode]_[qi|hdi]`, for example, `mean_qi`, `median_qi`, `mode_hdi`, and so on. The first name (before the `_`) indicates the type of point estimate, and the second name indicates the type of interval. `qi` yields a quantile interval (a.k.a. equi-tailed interval, central interval, or percentile interval) and `hdi` yields a highest (posterior) density interval. Custom estimates or intervals can also be applied using the `point_interval` function.

For example, we might gather the samples corresponding to the overall mean and standard deviation of observations:

```{r}
m %>%
  spread_samples(`(Intercept)`, sigma) %>%
  head(10)
```
*(10 rows of `r nrow(spread_samples(m, sigma))`)*

Like with `b[term,group,condition]`, this gives us a tidy data frame. If we want the mean and 95% quantile interval of the parameters, we can apply `mean_qi`:

```{r}
m %>%
  spread_samples(`(Intercept)`, sigma) %>%
  mean_qi(`(Intercept)`, sigma)
```

We can specify the columns we want to get means and intervals from, as above, or if we omit the list of columns, `mean_qi` will use every column that is not a grouping column or a special column (one that starts with `.`, like `.chain` or `.iteration`). Thus in the above example, `(Intercept)` and `sigma` are redundant arguments to `mean_qi` because they are also the only columns we gathered from the model. So we can simplify this to:

```{r}
m %>%
  spread_samples(`(Intercept)`, sigma) %>%
  mean_qi()
```

If you would rather have a long-format list of intervals, use `gather_samples` instead:

```{r}
m %>%
  gather_samples(`(Intercept)`, sigma) %>%
  mean_qi()
```

The `conf.low` and `conf.high` naming scheme is used when `mean_qi` summarizes a single column in order to be consistent with the output of `broom::tidy`. This makes it easier to compare output from `tidybayes` to other models supported by `broom`.

For more on `gather_samples`, see <code>[vignette("tidybayes")](tidybayes.html)</code>.

### With indexed parameters

When we have a parameter with one or more indices, such as `b`, we can apply `mean_qi` (or other functions in the `point_estimate` family) as we did before:

```{r}
m %>%
  spread_samples(b[,,condition]) %>%
  mean_qi()
```

How did `mean_qi` know what to aggregate? Data frames returned by `spread_samples` are automatically grouped by all index variables you pass to it; in this case, that means `spread_samples` groups its results by `condition`. `mean_qi` respects those groups, and calculates the estimates and intervals within all groups. Then, because no columns were passed to `mean_qi`, it acts on the only non-special (`.`-prefixed) and non-group column, `b`. So the above shortened syntax is equivalent to this more verbose call:

```{r}
m %>%
  spread_samples(b[,,condition]) %>%
  group_by(condition) %>%    # this line not necessary (done by spread_samples)
  mean_qi(b)                 # b is not necessary (it is the only non-group column)
```

## Combining variables with different indices in a single tidy format data frame

`spread_samples` supports gathering variables that have different indices in the same data frame. It automatically matches up indices with the same name, and duplicates values as necessary to produce one row per all combination of levels of all indices. For example, we might want to calculate the mean within each condition (call this `condition_mean`). In this model, that mean is the intercept (`(Intercept)`) plus the effect for a given condition (`b`). 

We can gather samples from `(Intercept)` and `b` together in a single data frame:

```{r}
m %>% 
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  head(10)
```
*(10 rows of `r nrow(spread_samples(m, b[term,group,condition]))`)*

Within each sample, `(Intercept)` is repeated as necessary to correspond to every index of `b`. Thus, the `mutate` function from dplyr can be used to find their sum, `condition_mean` (which is the estimated mean for each condition):

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mutate(condition_mean = `(Intercept)` + b) %>%
  mean_qi(condition_mean)
```

`mean_qi` can also take column expressions (rather than just column names), so we can simplify the above example by moving the calculation of `condition_mean` from `mutate` into `mean_qi`:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mean_qi(condition_mean = `(Intercept)` + b)
```

## Plotting point estimates and intervals

Plotting means and intervals is straightforward using the "pointrange" or "pointrangeh" geoms:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mean_qi(condition_mean = `(Intercept)` + b) %>%
  ggplot(aes(y = condition, x = condition_mean, xmin = conf.low, xmax = conf.high)) +
  geom_pointrangeh()
```


## Interval estimates with multiple probability levels

`mean_qi` and its sister functions can also produce an arbitrary number of probability intervals by setting the `.prob =` argument:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mean_qi(condition_mean = `(Intercept)` + b, .prob = c(.95, .8, .5))
```

The results are in a tidy format: one row per group and probability level (`.prob`). This facilitates plotting. For example, assigning `-.prob` to the `size` aesthetic will show all intervals, making thicker lines correspond to smaller intervals:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mean_qi(condition_mean = `(Intercept)` + b, .prob = c(.95, .8, .5)) %>%
  ggplot(aes(y = condition, x = condition_mean, xmin = conf.low, xmax = conf.high, 
    size = -.prob    # shorter interval => thicker line
  )) +
  geom_pointrangeh(
    fatten = 2         # smaller point estimate (otherwise it is very large)
  ) +
  scale_size_continuous(
    range = c(1, 2.5),   # default range is c(0, 6) --- makes very thick lines
    guide = FALSE      # no need for a legend on size
  )
```

## Making posterior predictions

We can use combinations of variables with difference indices to generate predictions from the model. In this case, we can combine the group means with the residual standard deviation to generate predictive distributions from the model:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition], sigma) %>%
  mutate(pred = rnorm(n(), `(Intercept)` + b, sigma)) %>%
  ggplot(aes(x = pred)) +
  stat_density() +
  facet_grid(condition ~ ., switch = "y")
```

And even summarize these as predictive intervals and compare to the data:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition], sigma) %>%
  mutate(pred = rnorm(n(), `(Intercept)` + b, sigma)) %>%
  mean_qi(pred, .prob = c(.95, .8, .5)) %>%
  ggplot(aes(x = condition, y = pred)) +
  geom_linerange(aes(ymin = conf.low, ymax = conf.high, 
    color = ordered(-.prob)),
    size = 4) +
  geom_point(aes(y = response), data = ABC) +
  scale_color_brewer(guide = FALSE)
```

If this model is well-calibrated, about 95% of the data should be in the outer intervals, 80% in the next-smallest intervals, and 50% in the smallest intervals.

Altogether, data, posterior predictions, and estimates of the means:

```{r}
samples = m %>%
  spread_samples(`(Intercept)`, b[,,condition], sigma) %>%
  mutate(mu = `(Intercept)` + b)

reps = samples %>%
  mutate(pred = rnorm(n(), mu, sigma)) %>%
  mean_qi(pred, .prob = c(.95, .8, .5))

parameters = samples %>%
  mean_qi(mu, .prob = c(.95, .66))

ABC %>%
  ggplot(aes(x = condition)) +
  geom_linerange(
    aes(ymin = conf.low, ymax = conf.high, 
      color = ordered(-.prob)),
    size = 4, 
    data = reps) +
  geom_pointrange(
    aes(y = mu, ymin = conf.low, ymax = conf.high, 
      size = -.prob),
    fatten = 1.5, position=position_nudge(x=0.3),
    data = parameters) +
  geom_point(aes(y = response)) +
  scale_color_brewer(guide = FALSE) +
  scale_size_continuous(range = c(1,2), guide = FALSE)
```

## Comparing levels of a factor

If we wish compare the means from each condition, `compare_levels` facilitates comparisons of the value of some variable across levels of a factor. By default it computes all pairwise differences:

```{r, fig.width=7}
#N.B. the syntax for compare_levels is experimental and may change
m %>%
  spread_samples(b[,,condition]) %>%
  compare_levels(b, by = condition) %>%
  ggplot(aes(x = condition, y = b)) +
  geom_violin(scale="width", fill="gray75", color=NA) +
  stat_summary(aes(size=-...prob..), 
    fun.data=median_qi, fun.args=list(.prob=c(.95,.66)), geom="pointrange", fatten=1.25)+
  scale_size_continuous(range=c(0.5,1.5), guide=FALSE) +
  coord_flip()
```

## Alternative estimates and intervals: mean, median, mode; qi, hdi

The `point_interval` family of functions follow the naming scheme `[mean|median|mode]_[qi|hdi]`, and all work in the same way as `mean_qi`: they take a series of names (or expressions calculated on columns) and summarize those columns with the corresponding point estimate (mean, median, or mode) and interval (qi or hdi). `qi` yields a quantile interval (a.k.a. equi-tailed interval, central interval, or percentile interval) and `hdi` yields a highest (posterior) density interval. These can be used in any combination desired. Replacing `mean_qi` with `mode_hdi` in the previous example yields mode and HDI instead of mean and quantile interval:

```{r}
m %>%
  spread_samples(`(Intercept)`, b[,,condition]) %>%
  mode_hdi(mu = `(Intercept)` + b) %>%
  ggplot(aes(x = condition, y = mu, ymin = conf.low, ymax = conf.high)) +
  geom_pointrange()
```

This is probably more noticeable given a skewed distribution, such as might be expected on a scale parameter:

```{r}
sd_samples = m %>% spread_samples(sigma)

rbind(
  sd_samples %>% mode_hdi(sigma) %>% mutate(type="mode_hdi"),
  sd_samples %>% mean_qi(sigma) %>% mutate(type="mean_qi")
) %>%
  ggplot(aes(x = sigma)) +
  stat_density(aes(y = ..scaled.. * 10), data = sd_samples, fill="gray75") +
  geom_point(aes(y = type)) +
  geom_errorbarh(aes(y = type, xmin = conf.low, xmax = conf.high), width=0)
```

